Starting evaluation of experiment OmniAnomaly-skab-valve1_12-68475eda2a5c3cb0de12f7a3dee4bd2b-1
=============================================

Performing training for SEMI_SUPERVISED algorithm OmniAnomaly
Running container 'ghcr.io/timeeval/omnianomaly:0.3.0' with env='{}' in ExecutionType.TRAIN mode.
Restricting container to 24.0 CPUs and 14.715 GB RAM

#### Docker container logs ####
2026-01-04 09:33:10.717651: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Train-val split: 0.19999999999999996
Trainable Parameters                                            (2,532,680 in total)
------------------------------------------------------------------------------------
model/q_z_given_x/rnn_q_z/rnn/gru_cell/gates/kernel             (508, 1000)  508,000
model/q_z_given_x/rnn_q_z/rnn/gru_cell/gates/bias               (1000,)        1,000
model/q_z_given_x/rnn_q_z/rnn/gru_cell/candidate/kernel         (508, 500)   254,000
model/q_z_given_x/rnn_q_z/rnn/gru_cell/candidate/bias           (500,)           500
model/q_z_given_x/rnn_q_z/dense/kernel                          (500, 500)   250,000
model/q_z_given_x/rnn_q_z/dense/bias                            (500,)           500
model/q_z_given_x/rnn_q_z/dense_1/kernel                        (500, 500)   250,000
model/q_z_given_x/rnn_q_z/dense_1/bias                          (500,)           500
model/vae/variational/z_mean/kernel                             (503, 3)       1,509
model/vae/variational/z_mean/bias                               (3,)               3
model/vae/variational/z_std/kernel                              (503, 3)       1,509
model/vae/variational/z_std/bias                                (3,)               3
model/posterior_flow/_0/w                                       (1, 3)             3
model/posterior_flow/_0/b                                       (1,)               1
model/posterior_flow/_0/u                                       (1, 3)             3
model/posterior_flow/_1/w                                       (1, 3)             3
model/posterior_flow/_1/b                                       (1,)               1
model/posterior_flow/_1/u                                       (1, 3)             3
model/posterior_flow/_2/w                                       (1, 3)             3
model/posterior_flow/_2/b                                       (1,)               1
model/posterior_flow/_2/u                                       (1, 3)             3
model/posterior_flow/_3/w                                       (1, 3)             3
model/posterior_flow/_3/b                                       (1,)               1
model/posterior_flow/_3/u                                       (1, 3)             3
model/posterior_flow/_4/w                                       (1, 3)             3
model/posterior_flow/_4/b                                       (1,)               1
model/posterior_flow/_4/u                                       (1, 3)             3
model/posterior_flow/_5/w                                       (1, 3)             3
model/posterior_flow/_5/b                                       (1,)               1
model/posterior_flow/_5/u                                       (1, 3)             3
model/posterior_flow/_6/w                                       (1, 3)             3
model/posterior_flow/_6/b                                       (1,)               1
model/posterior_flow/_6/u                                       (1, 3)             3
model/posterior_flow/_7/w                                       (1, 3)             3
model/posterior_flow/_7/b                                       (1,)               1
model/posterior_flow/_7/u                                       (1, 3)             3
model/posterior_flow/_8/w                                       (1, 3)             3
model/posterior_flow/_8/b                                       (1,)               1
model/posterior_flow/_8/u                                       (1, 3)             3
model/posterior_flow/_9/w                                       (1, 3)             3
model/posterior_flow/_9/b                                       (1,)               1
model/posterior_flow/_9/u                                       (1, 3)             3
model/posterior_flow/_10/w                                      (1, 3)             3
model/posterior_flow/_10/b                                      (1,)               1
model/posterior_flow/_10/u                                      (1, 3)             3
model/posterior_flow/_11/w                                      (1, 3)             3
model/posterior_flow/_11/b                                      (1,)               1
model/posterior_flow/_11/u                                      (1, 3)             3
model/posterior_flow/_12/w                                      (1, 3)             3
model/posterior_flow/_12/b                                      (1,)               1
model/posterior_flow/_12/u                                      (1, 3)             3
model/posterior_flow/_13/w                                      (1, 3)             3
model/posterior_flow/_13/b                                      (1,)               1
model/posterior_flow/_13/u                                      (1, 3)             3
model/posterior_flow/_14/w                                      (1, 3)             3
model/posterior_flow/_14/b                                      (1,)               1
model/posterior_flow/_14/u                                      (1, 3)             3
model/posterior_flow/_15/w                                      (1, 3)             3
model/posterior_flow/_15/b                                      (1,)               1
model/posterior_flow/_15/u                                      (1, 3)             3
model/posterior_flow/_16/w                                      (1, 3)             3
model/posterior_flow/_16/b                                      (1,)               1
model/posterior_flow/_16/u                                      (1, 3)             3
model/posterior_flow/_17/w                                      (1, 3)             3
model/posterior_flow/_17/b                                      (1,)               1
model/posterior_flow/_17/u                                      (1, 3)             3
model/posterior_flow/_18/w                                      (1, 3)             3
model/posterior_flow/_18/b                                      (1,)               1
model/posterior_flow/_18/u                                      (1, 3)             3
model/posterior_flow/_19/w                                      (1, 3)             3
model/posterior_flow/_19/b                                      (1,)               1
model/posterior_flow/_19/u                                      (1, 3)             3
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/gates/kernel      (503, 1000)  503,000
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/gates/bias        (1000,)        1,000
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/candidate/kernel  (503, 500)   251,500
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/candidate/bias    (500,)           500
model/p_x_given_z/hidden/rnn_p_x/dense/kernel                   (500, 500)   250,000
model/p_x_given_z/hidden/rnn_p_x/dense/bias                     (500,)           500
model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel                 (500, 500)   250,000
model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                   (500,)           500
model/p_x_given_z/x_mean/kernel                                 (500, 8)       4,000
model/p_x_given_z/x_mean/bias                                   (8,)               8
model/p_x_given_z/x_std/kernel                                  (500, 8)       4,000
model/p_x_given_z/x_std/bias                                    (8,)               8

train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with None/3.909804344177246 (old/new val loss)? Yes - Checkpoint created!
[Epoch 1/10, Step 100] step time: 0.1694s (±0.5428s); train time: 12.13s; valid time: 4.829s; loss: 1.05779e+10 (±6.24424e+10); valid loss: 6.46536 (*)
val_values: (1880, 8)
Should I create a checkpoint with 6.465360582269314/8.954477310180664 (old/new val loss)? No
train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with 4.578628353593415/-5.637715816497803 (old/new val loss)? Yes - Checkpoint created!
[Epoch 2/10, Step 200, ETA 3m 28.04s] step time: 0.1319s (±0.3812s); train time: 4.786s; valid time: 3.837s; loss: 13.2953 (±47.3362); valid loss: -0.781973 (*)
val_values: (1880, 8)
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/app/omni_anomaly/vae.py:460: DeprecationWarning: invalid escape sequence \*
  """
/app/omni_anomaly/vae.py:501: DeprecationWarning: invalid escape sequence \*
  """
/usr/local/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.
  compare_result = semver.compare(version, tf.__version__)
/usr/local/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.
  compare_result = semver.compare(version, tf.__version__)
Should I create a checkpoint with -0.7819733890181033/-2.9970154762268066 (old/new val loss)? Yes - Checkpoint created!
train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with -3.4845148322712336/62.06882095336914 (old/new val loss)? No
[Epoch 3/10, Step 300, ETA 3m 9.32s] step time: 0.1131s (±0.1896s); train time: 0.2068s; valid time: 1.903s; loss: 0.603918 (±8.23407); valid loss: 60.7927
val_values: (1880, 8)
Should I create a checkpoint with -3.4845148322712336/-1.8243926763534546 (old/new val loss)? No
[Epoch 3/10, Step 400, ETA 2m 41.52s] step time: 0.1153s (±0.1914s); train time: 9.622s; valid time: 1.922s; loss: 2.64403 (±11.866); valid loss: -2.79619
val_values: (1880, 8)
Should I create a checkpoint with -3.4845148322712336/0.6783046722412109 (old/new val loss)? No
train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with -3.4845148322712336/21.74729347229004 (old/new val loss)? No
[Epoch 4/10, Step 500, ETA 2m 24.27s] step time: 0.1171s (±0.1867s); train time: 5.129s; valid time: 1.875s; loss: -0.160231 (±9.07235); valid loss: 12.1537
val_values: (1880, 8)
Should I create a checkpoint with -3.4845148322712336/-0.8009859919548035 (old/new val loss)? No
train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with -3.4845148322712336/-13.330469131469727 (old/new val loss)? Yes - Checkpoint created!
[Epoch 5/10, Step 600, ETA 2m 11.49s] step time: 0.1393s (±0.4259s); train time: 0.3813s; valid time: 4.284s; loss: -0.449057 (±6.47001); valid loss: -4.98527 (*)
val_values: (1880, 8)
Should I create a checkpoint with -4.9852664118229155/-2.9944772720336914 (old/new val loss)? No
[Epoch 5/10, Step 700, ETA 1m 52.78s] step time: 0.1128s (±0.1835s); train time: 9.455s; valid time: 1.835s; loss: -1.93622 (±6.43897); valid loss: -3.95264
val_values: (1880, 8)
Should I create a checkpoint with -4.9852664118229155/-5.4243388175964355 (old/new val loss)? Yes - Checkpoint created!
train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with -4.9852664118229155/3.0074734687805176 (old/new val loss)? No
[Epoch 6/10, Step 800, ETA 1m 39.59s] step time: 0.1139s (±0.1857s); train time: 5.275s; valid time: 1.868s; loss: -2.25683 (±7.63422); valid loss: -2.29031
val_values: (1880, 8)
Should I create a checkpoint with -4.9852664118229155/-8.007262229919434 (old/new val loss)? Yes - Checkpoint created!
train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with -5.597692809930561/-18.697071075439453 (old/new val loss)? Yes - Checkpoint created!
[Epoch 7/10, Step 900, ETA 1m 28.54s] step time: 0.1378s (±0.409s); train time: 0.6258s; valid time: 4.109s; loss: -2.83536 (±9.3828); valid loss: -5.76407 (*)
val_values: (1880, 8)
Should I create a checkpoint with -5.7640723930520865/-6.43035888671875 (old/new val loss)? Yes - Checkpoint created!
[Epoch 7/10, Step 1000, ETA 1m 12.76s] step time: 0.1343s (±0.4267s); train time: 9.154s; valid time: 4.288s; loss: -1.65392 (±12.5647); valid loss: -2.68205
val_values: (1880, 8)
Should I create a checkpoint with -5.7640723930520865/-2.543123483657837 (old/new val loss)? No
train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with -5.7640723930520865/6.242234230041504 (old/new val loss)? No
[Epoch 8/10, Step 1100, ETA 57.33s] step time: 0.1141s (±0.1856s); train time: 5.406s; valid time: 1.864s; loss: -5.00701 (±5.13121); valid loss: -3.54262
val_values: (1880, 8)
Should I create a checkpoint with -5.7640723930520865/-0.8565500974655151 (old/new val loss)? No
train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with -5.7640723930520865/2.6005501747131348 (old/new val loss)? No
[Epoch 9/10, Step 1200, ETA 42.31s] step time: 0.1143s (±0.1826s); train time: 0.7539s; valid time: 1.832s; loss: -3.71582 (±7.9481); valid loss: -0.89675
val_values: (1880, 8)
Should I create a checkpoint with -5.7640723930520865/-8.864365577697754 (old/new val loss)? Yes - Checkpoint created!
[Epoch 9/10, Step 1300, ETA 27.7s] step time: 0.1442s (±0.4943s); train time: 9.465s; valid time: 4.967s; loss: -3.8916 (±7.44942); valid loss: -6.261 (*)
val_values: (1880, 8)
Should I create a checkpoint with -6.261003236024204/-6.99585485458374 (old/new val loss)? Yes - Checkpoint created!
train_values: (7521, 8)
val_values: (1880, 8)
Should I create a checkpoint with -6.261003236024204/-3.1861374378204346 (old/new val loss)? No
[Epoch 10/10, Step 1400, ETA 13.16s] step time: 0.113s (±0.1842s); train time: 5.48s; valid time: 1.854s; loss: -5.02902 (±4.86994); valid loss: -4.16338
val_values: (1880, 8)
Should I create a checkpoint with -6.261003236024204/6.78925895690918 (old/new val loss)? No

###############################

Performing execution for SEMI_SUPERVISED algorithm OmniAnomaly
Running container 'ghcr.io/timeeval/omnianomaly:0.3.0' with env='{}' in ExecutionType.EXECUTE mode.
Restricting container to 24.0 CPUs and 14.715 GB RAM

#### Docker container logs ####
2026-01-04 09:36:57.097625: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
------------------------------ testing ------------------------------
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/app/omni_anomaly/vae.py:460: DeprecationWarning: invalid escape sequence \*
  """
/app/omni_anomaly/vae.py:501: DeprecationWarning: invalid escape sequence \*
  """
/usr/local/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.
  compare_result = semver.compare(version, tf.__version__)
/usr/local/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.
  compare_result = semver.compare(version, tf.__version__)

###############################

Scoring algorithm OmniAnomaly with ROC_AUC metrics
Calculating ROC_AUC
  = 0.7866663960846786
